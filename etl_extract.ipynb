{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Extract Phase - DSA 2040A Mid Semester Exam\n",
    "\n",
    "**Course:** Data Warehousing & Mining  \n",
    "**Instructor:** Austin Odera  \n",
    "**Phase:** Extract (20 Marks)\n",
    "\n",
    "## Objective\n",
    "Extract and validate data from raw sources, identify quality issues, and prepare data for transformation.\n",
    "\n",
    "## Tasks Checklist\n",
    "- [ ] Load both datasets using Pandas\n",
    "- [ ] Display .head(), .info(), and .describe()\n",
    "- [ ] Identify and discuss at least three data quality issues\n",
    "- [ ] Merge datasets if relevant\n",
    "- [ ] Save validated copies to /data/\n",
    "- [ ] Document all observations with markdown cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main dataset\n",
    "# TODO: Update file path when raw_data.csv is available\n",
    "# raw_data = pd.read_csv('data/raw_data.csv')\n",
    "\n",
    "# Load incremental dataset\n",
    "# TODO: Update file path when incremental_data.csv is available\n",
    "# incremental_data = pd.read_csv('data/incremental_data.csv')\n",
    "\n",
    "print(\"Data loading section - files to be loaded once datasets are acquired\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about raw data\n",
    "# TODO: Uncomment and run when data is loaded\n",
    "# print(\"Raw Data Shape:\", raw_data.shape)\n",
    "# print(\"\\nRaw Data Head:\")\n",
    "# display(raw_data.head())\n",
    "# print(\"\\nRaw Data Info:\")\n",
    "# raw_data.info()\n",
    "# print(\"\\nRaw Data Description:\")\n",
    "# display(raw_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about incremental data\n",
    "# TODO: Uncomment and run when data is loaded\n",
    "# print(\"Incremental Data Shape:\", incremental_data.shape)\n",
    "# print(\"\\nIncremental Data Head:\")\n",
    "# display(incremental_data.head())\n",
    "# print(\"\\nIncremental Data Info:\")\n",
    "# incremental_data.info()\n",
    "# print(\"\\nIncremental Data Description:\")\n",
    "# display(incremental_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in raw data\n",
    "# TODO: Implement missing value analysis\n",
    "# missing_raw = raw_data.isnull().sum()\n",
    "# missing_pct_raw = (raw_data.isnull().sum() / len(raw_data)) * 100\n",
    "# \n",
    "# print(\"Missing Values in Raw Data:\")\n",
    "# missing_summary_raw = pd.DataFrame({\n",
    "#     'Missing Count': missing_raw,\n",
    "#     'Missing Percentage': missing_pct_raw\n",
    "# })\n",
    "# display(missing_summary_raw[missing_summary_raw['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Duplicate Records Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate records\n",
    "# TODO: Implement duplicate detection\n",
    "# duplicates_raw = raw_data.duplicated().sum()\n",
    "# duplicates_incremental = incremental_data.duplicated().sum()\n",
    "# \n",
    "# print(f\"Duplicate records in raw data: {duplicates_raw}\")\n",
    "# print(f\"Duplicate records in incremental data: {duplicates_incremental}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data Type Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and identify inconsistencies\n",
    "# TODO: Implement data type analysis\n",
    "# print(\"Raw Data Types:\")\n",
    "# print(raw_data.dtypes)\n",
    "# print(\"\\nIncremental Data Types:\")\n",
    "# print(incremental_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets if applicable\n",
    "# TODO: Implement data merging logic\n",
    "# combined_data = pd.concat([raw_data, incremental_data], ignore_index=True)\n",
    "# print(f\"Combined dataset shape: {combined_data.shape}\")\n",
    "# print(f\"Original raw data shape: {raw_data.shape}\")\n",
    "# print(f\"Incremental data shape: {incremental_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Validated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validated datasets\n",
    "# TODO: Save processed data files\n",
    "# raw_data.to_csv('data/validated_raw_data.csv', index=False)\n",
    "# incremental_data.to_csv('data/validated_incremental_data.csv', index=False)\n",
    "# combined_data.to_csv('data/validated_combined_data.csv', index=False)\n",
    "# \n",
    "# print(\"Validated data files saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary of Findings\n",
    "\n",
    "### Data Quality Issues Identified:\n",
    "1. **Issue 1:** [To be documented based on actual data]\n",
    "2. **Issue 2:** [To be documented based on actual data]\n",
    "3. **Issue 3:** [To be documented based on actual data]\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to transformation phase\n",
    "- Address identified quality issues\n",
    "- Apply necessary data cleaning and standardization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}